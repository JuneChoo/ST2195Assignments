{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "speeches = pd.read_excel(\"F:\\\\SynologyDrive\\\\LSE\\\\2023\\\\ST2195 Programming for Data Science\\\\Week6\\\\speeches.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "        date                                           contents\n0 2021-10-20     SPEECH  Overcoming the tragedy of the horiz...\n1 2021-10-19     SPEECH  “Hic sunt leones” – open research q...\n2 2021-10-19     SPEECH  The role of supervisors and central...\n3 2021-10-16     SPEECH  Globalisation after the pandemic   ...\n4 2021-10-14     SPEECH  IMFC Statement    Statement by Chri...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>contents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-10-20</td>\n      <td>SPEECH  Overcoming the tragedy of the horiz...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-10-19</td>\n      <td>SPEECH  “Hic sunt leones” – open research q...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-10-19</td>\n      <td>SPEECH  The role of supervisors and central...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-10-16</td>\n      <td>SPEECH  Globalisation after the pandemic   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-10-14</td>\n      <td>SPEECH  IMFC Statement    Statement by Chri...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "fx = pd.read_csv(\"F:\\\\SynologyDrive\\\\LSE\\\\2023\\\\ST2195 Programming for Data Science\\\\Week6\\\\fx.csv\", skiprows= 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "  Period\\Unit: [US dollar ]\n0   2021-11-16       1.1368\n1   2021-11-15       1.1444\n2   2021-11-12       1.1448\n3   2021-11-11       1.1460\n4   2021-11-10       1.1558",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Period\\Unit:</th>\n      <th>[US dollar ]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-11-16</td>\n      <td>1.1368</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-11-15</td>\n      <td>1.1444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-11-12</td>\n      <td>1.1448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-11-11</td>\n      <td>1.1460</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-11-10</td>\n      <td>1.1558</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "date         datetime64[ns]\nus dollar            object\ndtype: object"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "date        datetime64[ns]\ncontents            object\ndtype: object"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# 1. load and merge the datasets keeping all information available for the dates in which there is a measurement in “fx.csv”\n",
    "fx.rename(columns={\"Period\\\\Unit:\":\"date\", \"[US dollar ]\":\"us dollar\"},inplace=True)\n",
    "fx['date'] = pd.to_datetime(fx['date'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "speeches['date'] = pd.to_datetime(speeches['date'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "#fx_dates_df = fx.join(speeches,how=\"left\", on= \"date\")\n",
    "fx_dates_df  = pd.merge(fx, speeches, on ='date', how = 'left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "           date us dollar contents\n0    2021-11-16    1.1368      NaN\n1    2021-11-15    1.1444      NaN\n2    2021-11-12    1.1448      NaN\n3    2021-11-11    1.1460      NaN\n4    2021-11-10    1.1558      NaN\n...         ...       ...      ...\n6502 1999-01-08    1.1659      NaN\n6503 1999-01-07    1.1632      NaN\n6504 1999-01-06    1.1743      NaN\n6505 1999-01-05    1.1790      NaN\n6506 1999-01-04    1.1789      NaN\n\n[6507 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>us dollar</th>\n      <th>contents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-11-16</td>\n      <td>1.1368</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-11-15</td>\n      <td>1.1444</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-11-12</td>\n      <td>1.1448</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-11-11</td>\n      <td>1.1460</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-11-10</td>\n      <td>1.1558</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6502</th>\n      <td>1999-01-08</td>\n      <td>1.1659</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6503</th>\n      <td>1999-01-07</td>\n      <td>1.1632</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6504</th>\n      <td>1999-01-06</td>\n      <td>1.1743</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6505</th>\n      <td>1999-01-05</td>\n      <td>1.1790</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6506</th>\n      <td>1999-01-04</td>\n      <td>1.1789</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>6507 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_dates_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "2006-05-05    5\n2018-05-14    5\n2018-03-14    5\n2019-03-27    5\n2017-04-06    4\n             ..\n2013-10-28    1\n2013-10-29    1\n2013-10-30    1\n2013-10-31    1\n1999-01-04    1\nName: date, Length: 5919, dtype: int64"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Remove entries with obvious outliers or mistakes, if any.\n",
    "fx_dates_df['date'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aowu\\AppData\\Local\\Temp\\ipykernel_17884\\305582756.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  fx_dates_df.describe()\n"
     ]
    },
    {
     "data": {
      "text/plain": "                       date us dollar  \\\ncount                  6507      6507   \nunique                 5919      3588   \ntop     2006-05-05 00:00:00         -   \nfreq                      5        62   \nfirst   1999-01-04 00:00:00       NaN   \nlast    2021-11-16 00:00:00       NaN   \n\n                                                 contents  \ncount                                                2323  \nunique                                               2323  \ntop        SPEECH  Overcoming the tragedy of the horiz...  \nfreq                                                    1  \nfirst                                                 NaN  \nlast                                                  NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>us dollar</th>\n      <th>contents</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6507</td>\n      <td>6507</td>\n      <td>2323</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>5919</td>\n      <td>3588</td>\n      <td>2323</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>2006-05-05 00:00:00</td>\n      <td>-</td>\n      <td>SPEECH  Overcoming the tragedy of the horiz...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>5</td>\n      <td>62</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>first</th>\n      <td>1999-01-04 00:00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>last</th>\n      <td>2021-11-16 00:00:00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_dates_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "#3. Handle missing observations for the exchange rate, if any. This should be done replacing any missing exchange rate with the latest information available. Whenever this cannot be done, the relevant entry should be removed entirely from the dataset.\n",
    "fx_dates_df['us dollar'].fillna(method='bfill', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "date            0\nus dollar       0\ncontents     4184\ndtype: int64"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_dates_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17884\\3138267191.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#4. Calculate the exchange rate return. Extend the original dataset with the following variables: “good_news” (equal to 1 when the exchange rate return is larger than 0.5 percent, 0 otherwise) and “bad_news” (equal to 1 when the exchange rate return is lower than -0.5 percent, 0 otherwise)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mfx_dates_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'return'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfx_dates_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'us dollar'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiff\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m/\u001B[0m\u001B[0mfx_dates_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'us dollar'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mE:\\anaconda\\envs\\lsepy\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36mdiff\u001B[1;34m(self, periods)\u001B[0m\n\u001B[0;32m   2901\u001B[0m         \u001B[1;33m{\u001B[0m\u001B[0mexamples\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2902\u001B[0m         \"\"\"\n\u001B[1;32m-> 2903\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0malgorithms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdiff\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mperiods\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2904\u001B[0m         return self._constructor(result, index=self.index).__finalize__(\n\u001B[0;32m   2905\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"diff\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\envs\\lsepy\\lib\\site-packages\\pandas\\core\\algorithms.py\u001B[0m in \u001B[0;36mdiff\u001B[1;34m(arr, n, axis)\u001B[0m\n\u001B[0;32m   1777\u001B[0m         \u001B[0mlag_indexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_lag_indexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1778\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1779\u001B[1;33m         \u001B[0mout_arr\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mres_indexer\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marr\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mres_indexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlag_indexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1780\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1781\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mis_timedelta\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "#4. Calculate the exchange rate return. Extend the original dataset with the following variables: “good_news” (equal to 1 when the exchange rate return is larger than 0.5 percent, 0 otherwise) and “bad_news” (equal to 1 when the exchange rate return is lower than -0.5 percent, 0 otherwise)\n",
    "fx_dates_df['return'] = fx_dates_df['us dollar'].diff(-1)/fx_dates_df['us dollar']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"-\" at position 2709",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mE:\\anaconda\\envs\\lsepy\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.maybe_convert_numeric\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Unable to parse string \"-\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_17884\\1167371232.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfx_dates_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'us dollar'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_numeric\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfx_dates_df\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'us dollar'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mE:\\anaconda\\envs\\lsepy\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001B[0m in \u001B[0;36mto_numeric\u001B[1;34m(arg, errors, downcast)\u001B[0m\n\u001B[0;32m    183\u001B[0m         \u001B[0mcoerce_numeric\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0merrors\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"raise\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 185\u001B[1;33m             values, _ = lib.maybe_convert_numeric(\n\u001B[0m\u001B[0;32m    186\u001B[0m                 \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_numeric\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_numeric\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    187\u001B[0m             )\n",
      "\u001B[1;32mE:\\anaconda\\envs\\lsepy\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.maybe_convert_numeric\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Unable to parse string \"-\" at position 2709"
     ]
    }
   ],
   "source": [
    "fx_dates_df['us dollar'] = pd.to_numeric(fx_dates_df['us dollar'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fx[fx['exchange_rate'].isna()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx_dates_df['us dollar'].isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5. Remove the entries for which contents column has NA values. Generate and store in csv the following tables\n",
    "# a. “good_indicators” – with the 20 most common words (excluding articles, prepositions and similar connectors) associated with entries wherein “good_news” is equal to 1;\n",
    "# b. “bad_indicators” – with the 20 most common words (excluding articles, prepositions and similar connectors) associated with entries wherein “bad_news” is equal to 1"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
